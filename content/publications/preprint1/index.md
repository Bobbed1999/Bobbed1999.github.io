---
title: "Speaking Memories: A Multimodal Adaptive Dialogue Framework for Reminiscence Robotics"
authors:
- admin
date: "2025-10-02T00:00:00Z"

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article"]

# Publication name and optional abbreviated publication name.
publication: "IEEE Transactions on Robotics (T-RO)"
publication_short: "T-RO"

abstract: We present Speaking Memories, a multimodal adaptive dialogue framework designed for reminiscence robotics. This framework integrates auditory, visual, and textual inputs to support emotion-aware and personalized conversations with older adults, particularly those facing dementia. We have redesigned the system, using an edge-based interaction server that replaces the robot’s native hardware. This leads to a lower latency, improved robustness, and enhanced privacy. The new design couples a secure reminiscence media portal, a locally executed multimodal inference pipeline, and an embodied robotic agent into a scalable distributed system. We evaluate the framework through real-world deployments with older adults and caregivers, measuring both quantitative and qualitative metrics - including end-to-end latency, dialogue coherence, and interaction stability - as well as caregiver and participant evaluations of usability and engagement. The results demonstrate an end-to-end latency of under 6 seconds, high contextual coherence across dialogue turns, and consistently positive feedback from users and caregivers. We also release a structured multimodal dataset that synchronizes user inputs, affective cues, and system outputs to support future fine-tuning of vision-language and dialogue models. Together, these contributions establish Speaking Memories as a deployable and generalizable platform for adaptive reminiscence robotics.


# Summary. An optional shortened abstract.
summary: we present Speaking Memories, a robot-agnostic, host–edge multimodal dialogue framework designed for emotion-aware reminiscence interaction.

tags:
- T-RO

featured: true

hugoblox:
  ids:
    # arxiv: 1512.04133v1

links:
# - type: preprint
#   provider: arxiv
#   id: 1512.04133v1
# - type: code
#   url: https://github.com/HugoBlox/hugo-blox-builder
# - type: slides
#   url: https://www.slideshare.net/
# - type: dataset
#   url: "#"
# - type: poster
#   url: "#"
# - type: source
#   url: "#"
# - type: video
#   url: https://youtube.com
- type: custom
  label: Custom Link
  url: http://example.org

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: ''
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
- internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

This work is driven by the results in my [previous paper](/publications/conference-paper1/) on HRI.

<!-- > [!NOTE]
> Create your slides in Markdown - click the *Slides* button to check out the example.

Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
